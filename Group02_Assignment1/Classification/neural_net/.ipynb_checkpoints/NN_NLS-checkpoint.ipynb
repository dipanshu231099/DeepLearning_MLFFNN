{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "oooooooooooooooooooooo------------------------------------------------------------------------------ : 22%\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-38df3d053aac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_EPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-38df3d053aac>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentage_done\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpercentage_done\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentage_done\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mav_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_av_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mav_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_av_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-38df3d053aac>\u001b[0m in \u001b[0;36mepoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;31m#print(self.activation[-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0minstaneous_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue_value\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mtotal_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minstaneous_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2242\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "graphs_dir = 'nn_hidden/'\n",
    "def spit(filename , class_no):\n",
    "    f = open(filename)\n",
    "    df = []\n",
    "    i=0\n",
    "\n",
    "    for line in f:\n",
    "        l = line.split()\n",
    "        l = [float(i) for i in l]\n",
    "        df.append(l)\n",
    "        i=i+1\n",
    "    labels = []\n",
    "\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        ll = [0]*3\n",
    "        ll[class_no-1] = 1\n",
    "        ll = np.array(ll)\n",
    "        labels.append(ll)\n",
    "    labels = np.array(labels)\n",
    "    df = np.array(df)\n",
    "    return df,labels\n",
    "def logistic(a):\n",
    "    return (1/(1+math.exp(-a)))\n",
    "\n",
    "\n",
    "def relu(a):\n",
    "    if a>0:\n",
    "        return a\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def relu_derivative(a):\n",
    "    if a>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def linear(a):\n",
    "    return a\n",
    "\n",
    "def logistic_derivative(a):\n",
    "    return a*(1-a)\n",
    "\n",
    "def tan_hyperbolic(a):\n",
    "    None\n",
    "\n",
    "def get_data(filename):\n",
    "    data = np.genfromtxt(filename, delimiter=',')\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "def argm(vect):\n",
    "    maxi = -1000\n",
    "    ans = 0\n",
    "    for i in range(len(vect)):\n",
    "\n",
    "        if(vect[i][0]>maxi):\n",
    "            ans = i\n",
    "            maxi = vect[i][0]\n",
    "    return ans\n",
    "\n",
    "class Neural_Network():\n",
    "    data = None\n",
    "    layers = None\n",
    "    weights = None\n",
    "    del_weights = None\n",
    "    activation = None\n",
    "    activation_func = None\n",
    "    biases = None\n",
    "    MAX_EPOCH = 100\n",
    "    learning_rate = 0.001\n",
    "    data_x = None\n",
    "    data_y = None\n",
    "    def split_data(self):\n",
    "        data_x = self.data_x\n",
    "        data_y = self.data_y\n",
    "\n",
    "        self.train_x = data_x[:int(len(data_x)*0.6),:]\n",
    "        self.val_x = data_x[int(len(data_x)*0.6):int(len(data_x)*0.8),:]\n",
    "        self.test_x = data_x[int(len(data_x)*0.8):,:]\n",
    "\n",
    "        self.train_y = data_y[:int(len(data_y)*0.6),:]\n",
    "        self.val_y = data_y[int(len(data_y)*0.6):int(len(data_y)*0.8),:]\n",
    "        self.test_y = data_y[int(len(data_y)*0.8):,:]\n",
    "\n",
    "\n",
    "    def predict(self, samples):\n",
    "        predictions = []\n",
    "        for i in range(len(samples)):\n",
    "            self.activation[0] = np.reshape(samples[i], (samples[i].shape[0],1))\n",
    "            self.forward_pass()\n",
    "            predictions.append( self.activation[len(self.layers)])\n",
    "        return predictions\n",
    "\n",
    "    def construct(self, data_x,data_y, layers, activation_func):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        #input_dimen = data.shape[1]-1\n",
    "        input_dimen = 2\n",
    "        self.split_data()\n",
    "        self.layers = layers\n",
    "        self.weights = []\n",
    "        self.del_weights = []\n",
    "        self.biases = []\n",
    "        self.activation_func = activation_func\n",
    "        self.activation = [np.zeros((input_dimen, 1))]\n",
    "        for i in range(len(layers)):\n",
    "            self.activation.append(np.zeros((layers[i], 1)))\n",
    "            self.biases.append(0.01*np.random.random((layers[i],1)))\n",
    "            if i==0:\n",
    "                self.weights.append(0.01*np.random.random((input_dimen, layers[i])))\n",
    "                self.del_weights.append(0.01*np.random.random((input_dimen, layers[i])))\n",
    "            else:\n",
    "                self.weights.append(0.01*np.random.random((layers[i-1], layers[i])))\n",
    "                self.del_weights.append(0.01*np.random.random((layers[i-1], layers[i])))\n",
    "\n",
    "    def train(self):\n",
    "        self.history=[]\n",
    "        self.val_history=[]\n",
    "        for i in range (self.MAX_EPOCH):\n",
    "            percentage_done = i*100//self.MAX_EPOCH\n",
    "            print('o'*(percentage_done) + '-'*(100-percentage_done), \": \"+str(percentage_done)+\"%\",end='\\r')\n",
    "\n",
    "            av_error, val_av_error = self.epoch()\n",
    "            self.history.append((i+1, av_error))\n",
    "            self.val_history.append((i+1, val_av_error))\n",
    "            if(len(self.history)>1 and self.history[i][1]==self.history[i-1][1]):\n",
    "                break\n",
    "            # doing node wise ananlysis\n",
    "            if((i+1) % 500 == 0 ):\n",
    "                for layer in range(len(self.layers)):\n",
    "                    for node in range(self.layers[layer]):\n",
    "                        #pass\n",
    "                        self.node_wise_graph(node,layer,i)\n",
    "\n",
    "        percentage_done = 100\n",
    "        print('o'*(percentage_done) + '-'*(100-percentage_done), \": \"+str(percentage_done)+\"%\",end='\\r')\n",
    "        print()\n",
    "\n",
    "    def node_wise_graph(self, node, layer, e):\n",
    "        outcomes = []\n",
    "        for i in range(len(self.train_x)):\n",
    "            self.activation[0] = np.reshape(self.train_x[i,:], (self.train_x[i,:].shape[0],1))\n",
    "            self.true_value = np.reshape(self.train_y[i,:], (self.train_y[i,:].shape[0],1))\n",
    "            self.forward_pass()\n",
    "            outcomes.append(self.activation[layer+1][node][0])\n",
    "        train_x = self.train_x\n",
    "        ax = plt.axes(projection='3d')\n",
    "        label = \"Epoch\"+str(e+1)+\" Layer:\"+str(layer+1)+\" Node:\"+str(node+1)\n",
    "        ax.scatter3D(train_x[:,0], train_x[:,1], outcomes, label=label)\n",
    "        ax.set_xlabel(\"Attr1\")\n",
    "        ax.set_ylabel(\"Attr2\")\n",
    "        ax.set_zlabel('Value')\n",
    "        plt.legend()\n",
    "        plt.savefig(graphs_dir+label+'.png')\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    def epoch(self):\n",
    "        total_error = 0\n",
    "        val_total_error =0 \n",
    "        for i in range(len(self.train_x)):\n",
    "            self.activation[0] = np.reshape(self.train_x[i,:], (self.train_x[i,:].shape[0],1))\n",
    "            self.true_value = np.reshape(self.train_y[i,:], (self.train_y[i,:].shape[0],1))\n",
    "            #print(self.true_value)\n",
    "            #print(self.activation[-1])\n",
    "            self.forward_pass()\n",
    "            instaneous_error = 0.5*np.sum((self.true_value - self.activation[-1])**2)\n",
    "            total_error += instaneous_error\n",
    "            self.backward_pass()\n",
    "\n",
    "        for i in range(len(self.val_x)):\n",
    "            self.activation[0] = np.reshape(self.val_x[i,:], (self.val_x[i,:].shape[0],1))\n",
    "            self.true_value = np.reshape(self.val_y[i,:], (self.val_y[i,:].shape[0],1))\n",
    "            self.forward_pass()\n",
    "            instaneous_error = 0.5*np.sum((self.true_value - self.activation[-1])**2)\n",
    "            val_total_error += instaneous_error\n",
    "        \n",
    "        av_error = total_error/len(self.train_x)\n",
    "        val_av_error = val_total_error/len(self.val_x)\n",
    "        return av_error, val_av_error\n",
    "\n",
    "    def forward_pass(self):\n",
    "        for i in range(len(self.layers)):\n",
    "            self.forward_propagation_layer(i)\n",
    "            \n",
    "    \n",
    "    def forward_propagation_layer(self, current_layer):\n",
    "        self.activation[current_layer+1] = np.matmul(self.weights[current_layer].T, self.activation[current_layer])\n",
    "        self.activation[current_layer+1] += self.biases[current_layer]\n",
    "        for i in range(len(self.activation[current_layer+1])):\n",
    "            # print(self.activation[current_layer+1][i],end=' ')\n",
    "            self.activation[current_layer+1][i] = self.activation_func[current_layer](self.activation[current_layer+1][i])\n",
    "            # print(self.activation[current_layer+1][i])\n",
    "\n",
    "    def backward_pass(self):\n",
    "        for i in range(len(self.layers)-1, -1, -1):\n",
    "            self.backward_propagation_layer(i)\n",
    "\n",
    "    def backward_propagation_layer(self, current_layer):\n",
    "        if current_layer == len(self.layers)-1:\n",
    "            self.kronicker_delta = (self.true_value - self.activation[current_layer+1])    \n",
    "        else:\n",
    "            self.kronicker_delta = np.matmul(self.cache_weights, self.kronicker_delta)\n",
    "\n",
    "        if self.activation_func[current_layer] == logistic:\n",
    "            self.kronicker_delta *= logistic_derivative(self.activation[current_layer+1])\n",
    "        elif self.activation_func[current_layer] == linear:\n",
    "            self.kronicker_delta *= 1\n",
    "        elif self.activation_func == tan_hyperbolic:\n",
    "            self.kronicker_delta *= tan_hyperbolic_derivative(self.activation[current_layer+1])\n",
    "        elif self.activation_func == relu:\n",
    "            self.kronicker_delta *= relu_derivative(self.activation[current_layer+1])\n",
    "\n",
    "\n",
    "        self.del_weights[current_layer] = self.learning_rate * np.matmul(self.activation[current_layer] ,self.kronicker_delta.T)\n",
    "        self.cache_weights = self.weights[current_layer]\n",
    "        self.weights[current_layer] += self.del_weights[current_layer]\n",
    "        self.biases[current_layer] += self.learning_rate * self.kronicker_delta\n",
    "    \n",
    "    def train_prediction_graph(self):\n",
    "        train_x = self.train_x\n",
    "        train_y = self.train_y\n",
    "        train_pred = self.predict(train_x)\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.scatter3D(train_x[:,0], train_x[:,1], train_y, label='Actual')\n",
    "        ax.scatter3D(train_x[:,0], train_x[:,1], train_pred, label = \"Predicted\")\n",
    "        plt.title(\"Training\")\n",
    "        ax.set_xlabel(\"Attr1\")\n",
    "        ax.set_ylabel(\"Attr2\")\n",
    "        ax.set_zlabel('Value')\n",
    "        plt.legend()\n",
    "        plt.savefig(graphs_dir+'dist_train.png')\n",
    "        plt.close()\n",
    "\n",
    "    def val_prediction_graph(self):\n",
    "        val_x = self.val_x\n",
    "        val_y = self.val_y\n",
    "        val_pred = self.predict(val_x)\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.scatter3D(val_x[:,0], val_x[:,1], val_y, label='Actual')\n",
    "        ax.scatter3D(val_x[:,0], val_x[:,1], val_pred, label = \"Predicted\")\n",
    "        plt.title(\"validation\")\n",
    "        ax.set_xlabel(\"Attr1\")\n",
    "        ax.set_ylabel(\"Attr2\")\n",
    "        ax.set_zlabel('Value')\n",
    "        plt.legend()\n",
    "        plt.savefig(graphs_dir+'dist_val.png')\n",
    "        plt.close()\n",
    "\n",
    "    def test_prediction_graph(self):\n",
    "        test_x = self.test_x\n",
    "        test_y = self.test_y\n",
    "        test_pred = self.predict(test_x)\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.scatter3D(test_x[:,0], test_x[:,1], test_y, label='Actual')\n",
    "        ax.scatter3D(test_x[:,0], test_x[:,1], test_pred, label = \"Predicted\")\n",
    "        plt.title(\"testing\")\n",
    "        ax.set_xlabel(\"Attr1\")\n",
    "        ax.set_ylabel(\"Attr2\")\n",
    "        ax.set_zlabel('Value')\n",
    "        plt.legend()\n",
    "        plt.savefig(graphs_dir+'dist_test.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def train_vs_prediction_graph(self):\n",
    "        train_pred = self.predict(self.train_x)\n",
    "        plt.scatter(self.train_y, train_pred)\n",
    "        plt.title(\"Training Dataset\")\n",
    "        plt.savefig(graphs_dir+'actual_vs_pred_train.png')\n",
    "        plt.close()\n",
    "\n",
    "    def val_vs_prediction_graph(self):\n",
    "        val_pred = self.predict(self.val_x)\n",
    "        plt.scatter(self.val_y, val_pred)\n",
    "        plt.title(\"Val Dataset\")\n",
    "        plt.savefig(graphs_dir+'actual_vs_pred_val.png')\n",
    "        plt.close()\n",
    "\n",
    "    def test_vs_prediction_graph(self):\n",
    "        test_pred = self.predict(self.test_x)\n",
    "        plt.scatter(self.test_y, test_pred)\n",
    "        plt.title(\"Test Dataset\")\n",
    "        plt.savefig(graphs_dir+'actual_vs_pred_test.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def train_check(self):\n",
    "        out = model.predict(self.train_x)\n",
    "        out = np.array(out)\n",
    "        #print(out)\n",
    "        for i in range(len(out)):\n",
    "            temp = out[i]\n",
    "            temp_sum = temp.sum()\n",
    "            for j in range(len(temp)):\n",
    "                temp[j][0] = temp[j][0] / temp_sum\n",
    "            out[i] = temp \n",
    "\n",
    "        #print(out)\n",
    "        output = []\n",
    "        for i in range(len(out)):\n",
    "            temp = out[i]\n",
    "            tt = np.zeros(len(out[0]))\n",
    "\n",
    "            tt[argm(temp)] = 1\n",
    "\n",
    "            output.append(tt)\n",
    "        def onehot2class(onehot):\n",
    "            l = []\n",
    "            for val in onehot:\n",
    "                for i in range(len(val)):\n",
    "                    if(val[i]==1):\n",
    "                        l.append(i+1)\n",
    "            return l\n",
    "        output = np.array(output)\n",
    "        output = onehot2class(output)\n",
    "        true = onehot2class(self.train_y)\n",
    "        return output,true\n",
    "    \n",
    "    def test_check(self):\n",
    "        out = model.predict(self.test_x)\n",
    "        out = np.array(out)\n",
    "        #print(out)\n",
    "        for i in range(len(out)):\n",
    "            temp = out[i]\n",
    "            temp_sum = temp.sum()\n",
    "            for j in range(len(temp)):\n",
    "                temp[j][0] = temp[j][0] / temp_sum\n",
    "            out[i] = temp \n",
    "\n",
    "        #print(out)\n",
    "        output = []\n",
    "        for i in range(len(out)):\n",
    "            temp = out[i]\n",
    "            tt = np.zeros(len(out[0]))\n",
    "\n",
    "            tt[argm(temp)] = 1\n",
    "\n",
    "            output.append(tt)\n",
    "        def onehot2class(onehot):\n",
    "            l = []\n",
    "            for val in onehot:\n",
    "                for i in range(len(val)):\n",
    "                    if(val[i]==1):\n",
    "                        l.append(i+1)\n",
    "            return l\n",
    "        output = np.array(output)\n",
    "        output = onehot2class(output)\n",
    "        true = onehot2class(self.test_y)\n",
    "        return output,true\n",
    "    \n",
    "    \n",
    "    \n",
    "    def classify(self,sample_x):\n",
    "        out = model.predict(sample_x)\n",
    "        out = np.array(out)\n",
    "        #print(out)\n",
    "        for i in range(len(out)):\n",
    "            temp = out[i]\n",
    "            temp_sum = temp.sum()\n",
    "            for j in range(len(temp)):\n",
    "                temp[j][0] = temp[j][0] / temp_sum\n",
    "            out[i] = temp \n",
    "\n",
    "        #print(out)\n",
    "        output = []\n",
    "        for i in range(len(out)):\n",
    "            temp = out[i]\n",
    "            tt = np.zeros(len(out[0]))\n",
    "\n",
    "            tt[argm(temp)] = 1\n",
    "\n",
    "            output.append(tt)\n",
    "        def onehot2class(onehot):\n",
    "            l = []\n",
    "            for val in onehot:\n",
    "                for i in range(len(val)):\n",
    "                    if(val[i]==1):\n",
    "                        l.append(i+1)\n",
    "            return l\n",
    "        output = np.array(output)\n",
    "        output = onehot2class(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "data_x1 , data_y1 = spit('./Group02/Classification/Class1.txt',1)\n",
    "data_x2 , data_y2 = spit('./Group02/Classification/Class2.txt',2)\n",
    "data_x3 , data_y3 = spit('./Group02/Classification/Class3.txt',3)\n",
    "data_x = np.concatenate((data_x1,data_x2,data_x3) , axis=0)\n",
    "data_y = np.concatenate((data_y1 , data_y2 , data_y3) , axis=0)\n",
    "\n",
    "indices = np.arange(data_x.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "#normalize(data_x,axis=0)\n",
    "\n",
    "data_x = data_x[indices]\n",
    "data_y = data_y[indices]\n",
    "print(len(data_x))\n",
    "\n",
    "model = Neural_Network()\n",
    "model.construct(data_x,data_y, [3,3], [logistic,linear,logistic])\n",
    "model.learning_rate = 0.001\n",
    "model.MAX_EPOCH = 500\n",
    "model.train()\n",
    "\n",
    "\n",
    "plt.plot([model.history[i][0] for i in range(len(model.history))], [model.history[i][1] for i in range(len(model.history))], label='Training')\n",
    "plt.plot([model.history[i][0] for i in range(len(model.val_history))], [model.val_history[i][1] for i in range(len(model.val_history))], label='validation')\n",
    "plt.title('Epoch vs average error graph')\n",
    "plt.legend()\n",
    "plt.savefig(\"NN-Epoch vs average error graph NLS\")\n",
    "plt.show()\n",
    "a,b = model.train_check()\n",
    "c,d = model.test_check()\n",
    "def accuracy(a,b):\n",
    "    hits=0\n",
    "    for i in range(len(a)):\n",
    "        if(a[i]==b[i]):\n",
    "            hits = hits + 1\n",
    "    return hits/len(a)\n",
    "\n",
    "print(accuracy(a,b))\n",
    "print(accuracy(c,d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "xx =np.linspace(-8,8,num=500)\n",
    "yy = np.linspace(-8,8,num=500)\n",
    "for x in xx:\n",
    "    for y in yy:\n",
    "        tt = [x,y]\n",
    "        tt = np.array(tt)\n",
    "        tt = np.array([tt])\n",
    "        oo = model.classify(tt)\n",
    "        if(oo[0]==1):\n",
    "            class1.append(tt[0])\n",
    "        elif(oo[0]==2):\n",
    "            class2.append(tt[0])\n",
    "        else:\n",
    "            class3.append(tt[0])\n",
    "\n",
    "class3 = np.array(class3)\n",
    "class2 = np.array(class2)\n",
    "class1 = np.array(class1)        \n",
    "plt.scatter(class1[:,0],class1[:,1] , label=\"Class 1\")\n",
    "plt.scatter(class2[:,0] , class2[:,1] , label=\"Class 2\")\n",
    "plt.scatter(class3[:,0] , class3[:,1] , label=\"Class 3\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"NN DS for NLS\")\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
